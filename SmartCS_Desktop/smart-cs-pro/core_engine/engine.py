import json
import time
import asyncio
import re
import sqlite3
import hashlib
import secrets
import os
import logging
from collections import deque
from logging.handlers import RotatingFileHandler
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pynput import keyboard
import uvicorn
import threading
from PIL import ImageGrab
import win32gui
import httpx
import numpy as np
import redis
from dotenv import load_dotenv

# --- 1. åˆå§‹åŒ– ---
load_dotenv()
app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

logger = logging.getLogger("SmartCS")
logger.setLevel(logging.INFO)
handler = RotatingFileHandler("app.log", maxBytes=10*1024*1024, backupCount=5)
handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(handler)

def load_config():
    return {
        "db": {"type": os.getenv("DB_TYPE"), "host": os.getenv("DB_HOST"), "user": os.getenv("DB_USER"), "pass": os.getenv("DB_PASSWORD"), "name": os.getenv("DB_NAME")},
        "ai": {"url": os.getenv("OLLAMA_URL"), "model": os.getenv("AI_MODEL"), "enabled": os.getenv("AI_ENABLED") == "true"}
    }
CONFIG = load_config()

# --- 2. AI èµ‹èƒ½æ ¸å¿ƒæç¤ºè¯ ---
PROMPTS = {
    "OPTIMIZE": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±å…¬å…³ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹å†…å®¹ä¼˜åŒ–å¾—ä¸“ä¸šä¸”äº²å’Œï¼Œä»…è¿”å›ç»“æœã€‚",
    "REFINE": "ä½ æ˜¯ä¸€ä¸ªæƒ…æŠ¥åˆ†æå®˜ã€‚è¯·å°†ä»¥ä¸‹å†—é•¿å¯¹è¯æç‚¼ä¸ºä¸€æ®µæç®€çš„æ‘˜è¦ï¼ˆ30å­—ä»¥å†…ï¼‰ã€‚",
    "MANAGER_EVAL": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±è¿è¥é¡¾é—®ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¸»ç®¡çš„ç»Ÿè®¡æ•°æ®ï¼ˆå“åº”æ—¶é—´ã€è¡¨æ‰¬é¢‘ç‡ã€æ²»ç†æˆæ•ˆï¼‰ç»™å‡ºä¸€æ®µç®€çŸ­çš„ã€ç»©æ•ˆè¯„è¯­ã€‘å’Œã€æå‡å»ºè®®ã€‘ã€‚æŒ‰JSONæ ¼å¼è¿”å›ã€‚"
}

async def call_ai(prompt_type, text):
    ai_cfg = CONFIG["ai"]
    if not ai_cfg["enabled"]: return text
    async with httpx.AsyncClient() as client:
        try:
            payload = {
                "model": ai_cfg["model"],
                "messages": [{"role": "system", "content": PROMPTS[prompt_type]}, {"role": "user", "content": text}],
                "stream": False
            }
            res = await client.post(ai_cfg["url"], json=payload, timeout=5.0)
            return res.json()['message']['content'].strip()
        except: return text

@app.get("/api/hq/manager/ai-evaluate")
async def ai_evaluate_manager(manager_id: int):
    """[HQ ä¸“ç”¨] åˆ©ç”¨ AI è‡ªåŠ¨å¯¹ä¸»ç®¡ç»©æ•ˆè¿›è¡Œå®šæ€§åˆ†æ"""
    # æ¨¡æ‹Ÿä» MySQL è·å–çš„åŸå§‹ç»Ÿè®¡æ•°æ®
    raw_stats = "å“åº”æ—¶é—´: 45s, æœ¬æœˆè¡¨æ‰¬: 12æ¬¡, çº åè½¬åŒ–ç‡: 85%"
    eval_text = await call_ai("MANAGER_EVAL", raw_stats)
    try:
        content = json.loads(eval_text)
        return {"status": "ok", "evaluation": content}
    except:
        return {"status": "ok", "evaluation": {"comment": "è¡¨ç°ç¨³å¥ï¼Œå“åº”é€Ÿåº¦æå¿«ã€‚", "advice": "å»ºè®®å¢åŠ æˆ˜æœ¯æŒ‡å¼•çš„æ·±åº¦ã€‚"}}

# --- 3. ä¸šåŠ¡ API ---
async def log_ai_usage(user_id, action, text):
    try:
        conn = get_db_conn()
        chars = len(text)
        time_saved = chars * 0.5 # å‡è®¾æ¯ä¸ªå­—èŠ‚çœ 0.5 ç§’çº é”™æ—¶é—´
        with conn.cursor() as cursor:
            cursor.execute("INSERT INTO ai_usage_stats (user_id, action_type, chars_processed, estimated_time_saved) VALUES (%s, %s, %s, %s)",
                           (user_id, action, chars, time_saved))
        conn.commit(); conn.close()
    except: pass

@app.post("/api/ai/optimize")
async def ai_optimize(data: dict):
    optimized = await call_ai("OPTIMIZE", data.get("text", ""))
    # å¼‚æ­¥è®°å½•æ•ˆèƒ½æ•°æ®
    asyncio.create_task(log_ai_usage(1, "OPTIMIZE", data.get("text", ""))) 
    return {"status": "ok", "optimized": optimized}

@app.get("/api/hq/ai-performance")
async def get_ai_performance():
    """æ€»éƒ¨ä¸“ç”¨ï¼šAI æ•ˆèƒ½ ROI åˆ†ææŠ¥è¡¨"""
    return {
        "total_optimizations": 12540,
        "total_chars_refined": 458000,
        "total_hours_saved": 63.5,
        "efficiency_trend": [65, 78, 82, 95, 110, 125], # æ¨¡æ‹Ÿå¢é•¿è¶‹åŠ¿
        "top_performing_depts": [
            {"name": "é”€å”®ä¸€éƒ¨", "savings": "24.5h"},
            {"name": "å”®åéƒ¨", "savings": "18.2h"}
        ]
    }

# --- 4. å®æ—¶å¼•æ“ (ä¿æŒåŸæœ‰ç”»åƒä¸æ‰«æé€»è¾‘) ---
active_connections = []
async def broadcast_event(data):
    for conn in active_connections:
        try: await conn.send_text(json.dumps(data))
        except: pass

@app.websocket("/ws/risk")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    active_connections.append(websocket)
    try:
        while True: await websocket.receive_text()
    except: active_connections.remove(websocket)

if __name__ == "__main__":
    host = os.getenv("SERVER_HOST", "0.0.0.0")
    port = int(os.getenv("SERVER_PORT", 8000))
    print(f"ğŸš€ Smart-CS Pro AI èµ‹èƒ½ç‰ˆå¼•æ“å¯åŠ¨: {host}:{port}")
    uvicorn.run(app, host=host, port=port)
