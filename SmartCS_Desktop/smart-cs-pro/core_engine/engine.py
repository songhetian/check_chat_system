import json
import time
import asyncio
import re
import sqlite3
import hashlib
import secrets
import os
import logging
from collections import deque
from logging.handlers import RotatingFileHandler
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pynput import keyboard
import uvicorn
import threading
from PIL import ImageGrab
import win32gui
import httpx
import numpy as np
import redis
from dotenv import load_dotenv

# --- 1. åˆå§‹åŒ– ---
load_dotenv()
app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

logger = logging.getLogger("SmartCS")
logger.setLevel(logging.INFO)
handler = RotatingFileHandler("app.log", maxBytes=10*1024*1024, backupCount=5)
handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(handler)

def load_config():
    return {
        "db": {"type": os.getenv("DB_TYPE"), "host": os.getenv("DB_HOST"), "user": os.getenv("DB_USER"), "pass": os.getenv("DB_PASSWORD"), "name": os.getenv("DB_NAME")},
        "ai": {"url": os.getenv("OLLAMA_URL"), "model": os.getenv("AI_MODEL"), "enabled": os.getenv("AI_ENABLED") == "true"}
    }
CONFIG = load_config()

# --- 2. AI èµ‹èƒ½æ ¸å¿ƒæç¤ºè¯ ---
PROMPTS = {
    "OPTIMIZE": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±å…¬å…³ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹åå¸­è¾“å…¥çš„å†…å®¹ä¼˜åŒ–å¾—æ›´ä¸“ä¸šã€æ›´æœ‰äº²å’ŒåŠ›ï¼Œä¸”ä¸¥ç¦è¿è§„ã€‚ä»…è¿”å›ä¼˜åŒ–åçš„æ–‡æœ¬ã€‚",
    "SUMMARIZE": "ä½ æ˜¯ä¸€ä¸ªæˆ˜æœ¯åˆ†æå¸ˆã€‚è¯·å¯¹è¿™æ®µå¯¹è¯è®°å½•è¿›è¡Œæ·±åº¦æ€»ç»“ï¼Œåˆ—å‡ºï¼š1.å®¢æˆ·æ ¸å¿ƒè¯‰æ±‚ 2.æ½œåœ¨é£é™© 3.å¤„ç†å»ºè®®ã€‚æŒ‰JSONæ ¼å¼è¾“å‡ºã€‚"
}

async def call_ai(prompt_type, text):
    ai_cfg = CONFIG["ai"]
    if not ai_cfg["enabled"]: return text
    async with httpx.AsyncClient() as client:
        try:
            payload = {
                "model": ai_cfg["model"],
                "messages": [{"role": "system", "content": PROMPTS[prompt_type]}, {"role": "user", "content": text}],
                "stream": False
            }
            res = await client.post(ai_cfg["url"], json=payload, timeout=5.0)
            return res.json()['message']['content'].strip()
        except: return text

# --- 3. ä¸šåŠ¡ API ---
@app.post("/api/ai/optimize")
async def ai_optimize(data: dict):
    """åå¸­ç«¯ï¼šè¾“å…¥å†…å®¹å®æ—¶ä¼˜åŒ–"""
    optimized = await call_ai("OPTIMIZE", data.get("text", ""))
    return {"status": "ok", "optimized": optimized}

@app.post("/api/ai/summarize")
async def ai_summarize(data: dict):
    """ç®¡ç†ç«¯ï¼šè¿è§„å¤ç›˜æ™ºèƒ½æ€»ç»“"""
    summary = await call_ai("SUMMARIZE", data.get("context", ""))
    return {"status": "ok", "summary": summary}

# --- 4. å®æ—¶å¼•æ“ (ä¿æŒåŸæœ‰ç”»åƒä¸æ‰«æé€»è¾‘) ---
active_connections = []
async def broadcast_event(data):
    for conn in active_connections:
        try: await conn.send_text(json.dumps(data))
        except: pass

@app.websocket("/ws/risk")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    active_connections.append(websocket)
    try:
        while True: await websocket.receive_text()
    except: active_connections.remove(websocket)

if __name__ == "__main__":
    host = os.getenv("SERVER_HOST", "0.0.0.0")
    port = int(os.getenv("SERVER_PORT", 8000))
    print(f"ğŸš€ Smart-CS Pro AI èµ‹èƒ½ç‰ˆå¼•æ“å¯åŠ¨: {host}:{port}")
    uvicorn.run(app, host=host, port=port)
